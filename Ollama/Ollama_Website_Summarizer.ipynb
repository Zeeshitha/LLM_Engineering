{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58059d09-699a-40f6-9faa-98e8bc1b5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cea7ce8-1bf3-4011-a0b5-41c62e210e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b734e81e-03d4-4142-8353-a34aecffbc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c311c7c-84c6-46a9-acc1-c2d1e3573634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "October 16, 2024\n",
      "From Software Engineer to AI Data Scientist – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faea0439-00a3-4b6f-8a70-e71fe1619f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e1c537-8d71-4cff-ad64-71d2ee1e5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"The contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d01dfe-5942-4b02-96f8-ffd07879f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d11381f7-ba42-4ec6-8cd0-757c10c330c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the Ollama function instead of OpenAI\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    messages = messages_for(website)\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb2b2b03-fb54-49cf-9c26-0239d8904242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Summary of the LLM Tool in Azure Machine Learning Prompt Flow Website\\n\\nThe LLM tool in Azure Machine Learning prompt flow enables users to leverage large language models like OpenAI, Azure OpenAI Service, or Azure AI model inference API for natural language processing. The tool provides APIs for Completion and Chat, which facilitate interactive conversations with text-based inputs and responses.\\n\\n### Announcements\\n\\n* Note: The embedding option has been removed from the LLM tool API setting, and users can use an embedding API with the embedding tool instead.\\n* Tip: To use Microsoft Entra ID auth type for Azure OpenAI connection, assign either the Cognitive Services OpenAI User or Cognitive Services OpenAI Contributor role to a user or user-assigned managed identity.\\n\\n### Key Features\\n\\n#### Connections\\nUsers need to set up connections to provisioned resources in prompt flow, including name, API key, API type, and API version.\\n\\n#### Inputs (Text Completion)\\nThe following inputs are available for text completion:\\n\\n* `prompt`: Text prompt for the language model.\\n* `model, deployment_name`: Language model to use.\\n* `max_tokens`, `temperature`, `stop`, `suffix`, `top_p`, `logprobs`, and `echo` control various aspects of generated text.\\n\\n#### Inputs (Chat)\\nThe following inputs are available for chat:\\n\\n* `prompt`: Text prompt that the language model uses for a response.\\n* `model, deployment_name`: Language model to use. This parameter is not required if the model is deployed to a serverless API endpoint.\\n* Various parameters similar to those in text completion.\\n\\n#### Outputs\\nThe API returns strings as outputs for both Completion and Chat inputs.\\n\\n### Prerequisites\\n\\nUsers need to create OpenAI resources by signing up on the OpenAI website, finding their personal API key, and creating Azure OpenAI resources.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/tools-reference/llm-tool?view=azureml-api-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08d8e01f-e609-406f-9635-a085394476ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "521ebb20-34b3-4292-885f-1ea580075df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary of LLM Tool in Azure Machine Learning**\n",
       "=============================================\n",
       "\n",
       "The LLM tool in Azure Machine Learning is a platform for using large language models (LLMs) to process natural language inputs. It provides two APIs:\n",
       "\n",
       "*   **Completion**: Generates text based on provided prompts, using OpenAI's completion models.\n",
       "*   **Chat**: Facilitates interactive conversations with text-based inputs and responses, using OpenAI's chat models.\n",
       "\n",
       "The tool supports key-based authentication for Azure OpenAI connections and has specific requirements for resource group names and API keys.\n",
       "\n",
       "**Key Features**\n",
       "---------------\n",
       "\n",
       "*   Supports widely used LLMs like OpenAI and Azure OpenAI Service\n",
       "*   Provides text completion and chat APIs\n",
       "*   Allows users to set up connections to OpenAI resources or serverless API endpoints\n",
       "*   Configures large language model parameters, including temperature and top-p probabilities\n",
       "*   Includes features for managing prompt and response inputs\n",
       "\n",
       "**Prerequisites**\n",
       "-----------------\n",
       "\n",
       "To use the LLM tool, users need to:\n",
       "\n",
       "*   Create OpenAI resources and sign in with their personal API key\n",
       "*   Deploy models to serverless API endpoints using the Azure AI model inference API"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/tools-reference/llm-tool?view=azureml-api-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2f7eb-baa6-4eaf-b1bd-beb337e033b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
